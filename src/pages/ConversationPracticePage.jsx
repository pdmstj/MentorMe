import React, { useRef, useEffect, useState } from 'react';
import { useNavigate } from 'react-router-dom';
import '../pages/ConversationPracticePage.css';
import frame34 from "../image/Frame 34.svg";
import ai_men from "../image/aimento.png";
import logoImg from "../image/mentorme_logo.png";

const questions = [
  { tag: 'ë¬¸ì œí•´ê²° ì—­ëŸ‰', text: 'ê³¼ì œë‚˜ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•˜ëŠ” ê³¼ì •ì—ì„œ ë¬¸ì œê°€ ë°œìƒí•˜ì—¬ í•´ê²°í–ˆë˜ ê²½í—˜ì— ëŒ€í•´ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”.' },
  { tag: 'í˜‘ì—… ê²½í—˜', text: 'íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ê°ˆë“±ì´ ìˆì—ˆë˜ ê²½í—˜ê³¼ ì–´ë–»ê²Œ í•´ê²°í–ˆëŠ”ì§€ ë§ì”€í•´ì£¼ì„¸ìš”.' },
  { tag: 'ì„±ì¥ ê²½í—˜', text: 'ë³¸ì¸ì´ ì„±ì¥í–ˆë‹¤ê³  ëŠê¼ˆë˜ ê²½í—˜ì— ëŒ€í•´ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”.' },
  { tag: 'ì§€ì› ë™ê¸°', text: 'í•´ë‹¹ ì§ë¬´ë‚˜ íšŒì‚¬ì— ì§€ì›í•˜ê²Œ ëœ ê³„ê¸°ë¥¼ ë§ì”€í•´ì£¼ì„¸ìš”.' }
];

const ConversationPracticePage = () => {
  const videoRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const chunksRef = useRef([]);
  const [mediaStream, setMediaStream] = useState(null);
  const [recording, setRecording] = useState(false);
  const [recordedBlob, setRecordedBlob] = useState(null);
  const [questionIndex, setQuestionIndex] = useState(0);
  const [recordingTime, setRecordingTime] = useState(0);
  const navigate = useNavigate();

  // ğŸŸ¢ Whisper ì„œë²„ì— ì—…ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
  const uploadToWhisper = async (blob) => {
    const formData = new FormData();
    formData.append("file", blob, "audio.wav");

    try {
      const response = await fetch('http://localhost:8000/stt/', {
        method: 'POST',
        body: formData,
      });

      const data = await response.json();
      console.log('STT ê²°ê³¼:', data.text);
      return data.text;
    } catch (error) {
      console.error('STT ì—…ë¡œë“œ ì‹¤íŒ¨:', error);
      return null;
    }
  };

  // ì§ˆë¬¸ ìë™ ì „í™˜
  useEffect(() => {
    const timer = setInterval(() => {
      setQuestionIndex((prev) => (prev + 1) % questions.length);
    }, 30000);
    return () => clearInterval(timer);
  }, []);

  // ìë™ ë…¹í™” ì‹œì‘
  useEffect(() => {
    const startAutoRecording = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        setMediaStream(stream);
        if (videoRef.current) videoRef.current.srcObject = stream;

        const mediaRecorder = new MediaRecorder(stream);
        mediaRecorderRef.current = mediaRecorder;
        chunksRef.current = [];

        mediaRecorder.ondataavailable = (e) => {
          if (e.data.size > 0) {
            chunksRef.current.push(e.data);
          }
        };

        // ë…¹í™” ì¢…ë£Œ -> Whisper ì„œë²„ë¡œ ì „ì†¡
        mediaRecorder.onstop = async () => {
          const blob = new Blob(chunksRef.current, { type: 'audio/webm' });
          setRecordedBlob(blob);
          stream.getTracks().forEach(track => track.stop());

          const sttText = await uploadToWhisper(blob); // ğŸ”¥ STT í…ìŠ¤íŠ¸ ë°›ì•„ì˜¤ê¸°
          const videoUrl = URL.createObjectURL(blob);

          navigate('/feedback', { state: { videoUrl, sttText } }); // â” í”¼ë“œë°± í˜ì´ì§€ë¡œ ì „ë‹¬
        };

        mediaRecorder.start();
        setRecording(true);
      } catch (err) {
        console.error('ì¹´ë©”ë¼/ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜:', err);
      }
    };

    startAutoRecording();
  }, []);

  // ë…¹í™” íƒ€ì´ë¨¸
  useEffect(() => {
    let interval;
    if (recording) {
      interval = setInterval(() => {
        setRecordingTime((prev) => prev + 1);
      }, 1000);
    }
    return () => clearInterval(interval);
  }, [recording]);

  const formatTime = (seconds) => {
    const m = String(Math.floor(seconds / 60)).padStart(2, '0');
    const s = String(seconds % 60).padStart(2, '0');
    return `${m}:${s}`;
  };

  const handleFeedbackClick = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop(); // onstopì—ì„œ ì„œë²„ ì „ì†¡ í›„ ì´ë™
      setRecording(false);
    } else if (recordedBlob) {
      const videoUrl = URL.createObjectURL(recordedBlob);
      navigate('/feedback', { state: { videoUrl } });
    } else {
      alert('ë…¹í™”ëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.');
    }
  };

  return (
    <>
      <div className="header-container">
        <div className="title-box">
          <div className="title-logo">
            <img src={logoImg} alt="ë¡œê³ " className='logo-img'/>
          </div>
          <span className="title-text">ëŒ€í™”í˜• ì‹¤ì „ ë©´ì ‘</span>
        </div>
        <button className="exit-button" onClick={() => navigate('/')}>ë‚˜ê°€ê¸°</button>
      </div>
      <hr className='hrline' />
      <div className="interview-container">
        <div className="question-container">
          <img className="img" alt="Frame" src={frame34} />
          <div className="question-section">
            <span className="question-tag">ğŸ§  {questions[questionIndex].tag}</span>
            <p className="question-text">{questions[questionIndex].text}</p>
          </div>
        </div>

        <div className="interview-video-section">
          <div className="ai-interviewer">
            <p>AI ë©´ì ‘ê´€ í™”ë©´</p>
            <img src={ai_men} alt="AI ë©´ì ‘ê´€" className="face-image" />
          </div>

          <div className="user-camera">
            <p>ë‚˜ì˜ í™”ë©´</p>
            <video ref={videoRef} autoPlay muted className="video-preview" />

            {recording && (
              <div className="recording-bar">
                <div className="recording-indicator">ğŸ”´ ë…¹í™”ì¤‘ {formatTime(recordingTime)}</div>
                <div className="waveform">
                  <div className="bar"></div>
                  <div className="bar"></div>
                  <div className="bar"></div>
                  <div className="bar"></div>
                  <div className="bar"></div>
                </div>
                <button className="feedback-button" onClick={handleFeedbackClick}>í”¼ë“œë°± ë³´ëŸ¬ê°€ê¸°</button>
              </div>
            )}
          </div>
        </div>
      </div>
    </>
  );
};

export default ConversationPracticePage;
